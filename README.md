# ðŸ›ï¸ Gov Contracts AI

> **Sistema Open Source de Auditoria em LicitaÃ§Ãµes Governamentais Brasileiras**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)]()
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)]()
[![Next.js](https://img.shields.io/badge/Next.js-14-black)]()
[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)]()
[![Open Source](https://img.shields.io/badge/Open%20Source-%E2%9D%A4-brightgreen)]()

**Gerando achados de auditoria automatizados em licitaÃ§Ãµes pÃºblicas** usando **Machine Learning** (XGBoost) + **IA Generativa** (Llama 3.1) + **NLP** (BERT).

---

## ðŸ’¡ Proposta de Valor

**Problema:** BilhÃµes perdidos anualmente em irregularidades em licitaÃ§Ãµes (TCU)

**SoluÃ§Ã£o:** AnÃ¡lise automatizada de 50k+ licitaÃ§Ãµes com 85%+ de precisÃ£o
**Impacto:** Auditoria proativa antes da homologaÃ§Ã£o, explicaÃ§Ãµes em portuguÃªs, 100% auditÃ¡vel

---

## ðŸŒŸ Diferenciais

| Aspecto | SoluÃ§Ãµes Existentes | Gov Contracts AI |
|---------|---------------------|------------------|
| **Open Source** | âŒ ProprietÃ¡rio | âœ… GPL v3.0 |
| **Soberania** | âŒ Cloud externas | âœ… On-premises |
| **IA Generativa** | âŒ Apenas ML | âœ… LLM + ML hÃ­brido |
| **Editais PDF** | âŒ NÃ£o analisa | âœ… NLP avanÃ§ado |
| **PreÃ§os Mercado** | âŒ Sem referÃªncia | âœ… Web scraping |
| **Explicabilidade** | âš ï¸ BÃ¡sica | âœ… SHAP + LLM |

---

## ðŸ“Š Portfolio Project - ML/AI Engineer

---

## ðŸ“‹ Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Objetivos e Justificativas](#objetivos-e-justificativas)
3. [Arquitetura do Sistema](#arquitetura-do-sistema)
4. [Stack TecnolÃ³gica Completa](#stack-tecnolÃ³gica-completa)
5. [Estrutura do Projeto](#estrutura-do-projeto)
6. [Roadmap Detalhado - 5 Meses](#roadmap-detalhado)
7. [Guia de ImplementaÃ§Ã£o Fase por Fase](#guia-de-implementaÃ§Ã£o)
8. [CritÃ©rios de Sucesso](#critÃ©rios-de-sucesso)
9. [DocumentaÃ§Ã£o e ApresentaÃ§Ã£o](#documentaÃ§Ã£o-e-apresentaÃ§Ã£o)
10. [PrÃ³ximos Passos Imediatos](#prÃ³ximos-passos-imediatos)

---

## ðŸŽ¯ VisÃ£o Geral

### Problema de NegÃ³cio

O Brasil gasta anualmente mais de **R$ 500 bilhÃµes** em licitaÃ§Ãµes pÃºblicas. Estudos do TCU (Tribunal de Contas da UniÃ£o) indicam que atÃ© **15% dos contratos** apresentam indÃ­cios de sobrepreÃ§o, representando bilhÃµes em desperdÃ­cio de recursos pÃºblicos.

### SoluÃ§Ã£o Proposta

Sistema end-to-end que combina:
- **ML ClÃ¡ssico** (XGBoost) para detecÃ§Ã£o quantitativa de anomalias de preÃ§o
- **AI Generativa** (LLMs) para anÃ¡lise qualitativa de editais e explicabilidade
- **NLP** para identificar clÃ¡usulas restritivas e padrÃµes textuais suspeitos
- **RAG** para busca semÃ¢ntica e anÃ¡lise comparativa

### Valor para Portfolio

Este projeto demonstra proficiÃªncia em:
- âœ… **ML Engineering**: pipelines, feature engineering, deploy, MLOps
- âœ… **AI Engineering**: LLMs, RAG, vector databases, prompt engineering
- âœ… **Data Engineering**: ETL, data quality, orquestraÃ§Ã£o
- âœ… **Full Stack**: API REST, frontend moderno, UX
- âœ… **DevOps**: Docker, CI/CD, cloud, monitoring

---

## ðŸŽ¯ Objetivos e Justificativas

### Objetivo Principal
**Conseguir primeiro emprego como ML Engineer ou AI Engineer** em empresas que valorizam:
- Projetos end-to-end completos
- CÃ³digo production-ready
- Conhecimento hÃ­brido (ML clÃ¡ssico + AI generativa)
- Impacto social mensurÃ¡vel

### Por que este projeto?

#### âœ… Problema Real e Relevante
- **Impacto social**: combate Ã  corrupÃ§Ã£o e desperdÃ­cio pÃºblico
- **Dados acessÃ­veis**: APIs governamentais abertas (PNCP, Compras.gov.br)
- **MensurÃ¡vel**: mÃ©tricas claras de sucesso (economia estimada)

#### âœ… Complexidade Adequada
- **NÃ£o Ã© trivial**: requer feature engineering sofisticado
- **NÃ£o Ã© impossÃ­vel**: escopo realizÃ¡vel em 5 meses
- **EscalÃ¡vel**: pode adicionar features progressivamente

#### âœ… DiferenciaÃ§Ã£o no Mercado
- **Maioria dos portfolios**: projetos Kaggle ou tutoriais genÃ©ricos
- **Seu projeto**: problema Ãºnico, dados brasileiros, impacto real
- **HÃ­brido ML+AI**: 95% dos jÃºniores focam em apenas uma Ã¡rea

#### âœ… Demonstra Maturidade TÃ©cnica
- **MLOps**: nÃ£o Ã© "notebook sujo", Ã© sistema em produÃ§Ã£o
- **Testes**: coverage >85%
- **DocumentaÃ§Ã£o**: nÃ­vel profissional
- **Deploy**: aplicaÃ§Ã£o rodando em cloud pÃºblica

---

## ðŸ—ï¸ Arquitetura do Sistema

### Diagrama de Alto NÃ­vel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAMADA DE INGESTÃƒO                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data Sources:                                                  â”‚
â”‚  â€¢ PNCP API (licitaÃ§Ãµes oficiais)                               â”‚
â”‚  â€¢ Compras.gov.br API                                           â”‚
â”‚  â€¢ Web scraping (preÃ§os de mercado - Ã©tico)                     â”‚
â”‚  â€¢ TCU datasets (histÃ³ricos)                                    â”‚
â”‚                                                                 â”‚
â”‚  Schedulers:                                                    â”‚
â”‚  â€¢ Prefect Flows (orquestraÃ§Ã£o)                                 â”‚
â”‚  â€¢ Daily ingestion (licitaÃ§Ãµes novas)                           â”‚
â”‚  â€¢ Weekly refresh (preÃ§os mercado)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CAMADA DE ARMAZENAMENTO                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data Lake (AWS S3):                                            â”‚
â”‚  â”œâ”€â”€ bronze/ (raw data, particionado por data)                  â”‚
â”‚  â”œâ”€â”€ silver/ (cleaned, validated)                               â”‚
â”‚  â””â”€â”€ gold/ (features, aggregations)                             â”‚
â”‚                                                                 â”‚
â”‚  Data Warehouse (PostgreSQL):                                   â”‚
â”‚  â”œâ”€â”€ staging (dados brutos)                                     â”‚
â”‚  â”œâ”€â”€ dwh (schema estrela otimizado)                             â”‚
â”‚  â””â”€â”€ ml_features (tabelas desnormalizadas)                      â”‚
â”‚                                                                 â”‚
â”‚  Vector Store (Pinecone):                                       â”‚
â”‚  â””â”€â”€ editais embeddings (busca semÃ¢ntica)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CAMADA DE PROCESSAMENTO                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ETL Pipelines:                                                 â”‚
â”‚  â€¢ Data validation (Great Expectations)                         â”‚
â”‚  â€¢ Data cleaning (Pandas/Polars)                                â”‚
â”‚  â€¢ Feature engineering (30+ features)                           â”‚
â”‚  â€¢ DVC tracking (versionamento)                                 â”‚
â”‚                                                                 â”‚
â”‚  Data Quality:                                                  â”‚
â”‚  â€¢ Schema validation                                            â”‚
â”‚  â€¢ Null checks                                                  â”‚
â”‚  â€¢ Outlier detection                                            â”‚
â”‚  â€¢ Drift monitoring                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CAMADA ML TRADICIONAL                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Training Pipeline:                                             â”‚
â”‚  â€¢ Baseline models (Logistic Reg, Random Forest)                â”‚
â”‚  â€¢ Production models (XGBoost, LightGBM)                        â”‚
â”‚  â€¢ Hyperparameter tuning (Optuna)                               â”‚
â”‚  â€¢ Cross-validation (stratified)                                â”‚
â”‚                                                                 â”‚
â”‚  Experiment Tracking:                                           â”‚
â”‚  â€¢ MLflow (metrics, params, artifacts)                          â”‚
â”‚  â€¢ Model registry (staging/production)                          â”‚
â”‚  â€¢ Model versioning                                             â”‚
â”‚                                                                 â”‚
â”‚  Model Artifacts:                                               â”‚
â”‚  â€¢ Trained models (pickle/ONNX)                                 â”‚
â”‚  â€¢ Feature transformers                                         â”‚
â”‚  â€¢ SHAP explainer                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CAMADA AI GENERATIVA                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LLM Services:                                                  â”‚
â”‚  â€¢ Claude API (explicaÃ§Ãµes para cidadÃ£os)                       â”‚
â”‚  â€¢ GPT-4 (anÃ¡lise complexa de editais)                          â”‚
â”‚  â€¢ Prompt templates versionados                                 â”‚
â”‚  â€¢ Token usage tracking                                         â”‚
â”‚                                                                 â”‚
â”‚  NLP Pipeline:                                                  â”‚
â”‚  â€¢ BERT Portuguese (classificaÃ§Ã£o clÃ¡usulas)                    â”‚
â”‚  â€¢ Named Entity Recognition (empresas, valores)                 â”‚
â”‚  â€¢ Sentiment analysis (linguagem vaga/especÃ­fica)               â”‚
â”‚                                                                 â”‚
â”‚  RAG System:                                                    â”‚
â”‚  â€¢ Document chunking (editais)                                  â”‚
â”‚  â€¢ Embeddings (OpenAI ada-002)                                  â”‚
â”‚  â€¢ Vector search (Pinecone)                                     â”‚
â”‚  â€¢ Context retrieval + LLM generation                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAMADA DE SERVIÃ‡O                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  FastAPI Application:                                           â”‚
â”‚  â”œâ”€â”€ /v1/predict (ML model inference)                           â”‚
â”‚  â”œâ”€â”€ /v1/explain (SHAP values + LLM explanation)                â”‚
â”‚  â”œâ”€â”€ /v1/search (RAG - busca semÃ¢ntica)                         â”‚
â”‚  â”œâ”€â”€ /v1/analyze-edital (NLP analysis)                          â”‚
â”‚  â”œâ”€â”€ /v1/batch (processamento em lote)                          â”‚
â”‚  â””â”€â”€ /v1/health (healthcheck + metrics)                         â”‚
â”‚                                                                 â”‚
â”‚  Background Workers:                                            â”‚
â”‚  â€¢ Celery (async tasks)                                         â”‚
â”‚  â€¢ Redis (message broker + cache)                               â”‚
â”‚  â€¢ Scheduled jobs (retraining, reports)                         â”‚
â”‚                                                                 â”‚
â”‚  Caching Layer:                                                 â”‚
â”‚  â€¢ Redis (predictions cache - 24h TTL)                          â”‚
â”‚  â€¢ Model loading (in-memory)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FRONTEND                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Next.js 14 Application:                                        â”‚
â”‚  â€¢ Server Components (performance)                              â”‚
â”‚  â€¢ Streaming responses (LLM real-time)                          â”‚
â”‚  â€¢ shadcn/ui (componentes modernos)                             â”‚
â”‚  â€¢ Tailwind CSS (styling)                                       â”‚
â”‚                                                                 â”‚
â”‚  Features:                                                      â”‚
â”‚  â”œâ”€â”€ Dashboard (KPIs, alertas)                                  â”‚
â”‚  â”œâ”€â”€ Busca/Filtros (licitaÃ§Ãµes)                                 â”‚
â”‚  â”œâ”€â”€ AnÃ¡lise Individual (detalhes + explicaÃ§Ã£o)                 â”‚
â”‚  â”œâ”€â”€ Comparativo (licitaÃ§Ã£o vs mercado)                         â”‚
â”‚  â”œâ”€â”€ Explicabilidade Visual (SHAP plots)                        â”‚
â”‚  â”œâ”€â”€ Busca SemÃ¢ntica (RAG interface)                            â”‚
â”‚  â””â”€â”€ RelatÃ³rios (PDF export)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CAMADA DE OBSERVABILIDADE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Application Monitoring:                                        â”‚
â”‚  â€¢ Prometheus (mÃ©tricas)                                        â”‚
â”‚  â€¢ Grafana (dashboards)                                         â”‚
â”‚  â€¢ Sentry (error tracking)                                      â”‚
â”‚  â€¢ CloudWatch Logs                                              â”‚
â”‚                                                                 â”‚
â”‚  ML Monitoring:                                                 â”‚
â”‚  â€¢ Evidently AI (data/concept drift)                            â”‚
â”‚  â€¢ Custom metrics (precision, recall por categoria)             â”‚
â”‚  â€¢ Model performance tracking                                   â”‚
â”‚  â€¢ A/B test analytics (se aplicÃ¡vel)                            â”‚
â”‚                                                                 â”‚
â”‚  Cost Tracking:                                                 â”‚
â”‚  â€¢ AWS costs por serviÃ§o                                        â”‚
â”‚  â€¢ LLM API costs (tokens)                                       â”‚
â”‚  â€¢ Alert thresholds                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  INFRAESTRUTURA                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  AWS Services:                                                  â”‚
â”‚  â€¢ ECS Fargate (containers serverless)                          â”‚
â”‚  â€¢ RDS PostgreSQL (managed database)                            â”‚
â”‚  â€¢ S3 (data lake + static assets)                               â”‚
â”‚  â€¢ ElastiCache Redis (cache + queue)                            â”‚
â”‚  â€¢ Application Load Balancer                                    â”‚
â”‚  â€¢ CloudWatch (logs + metrics)                                  â”‚
â”‚  â€¢ Secrets Manager (API keys)                                   â”‚
â”‚                                                                 â”‚
â”‚  Infrastructure as Code:                                        â”‚
â”‚  â€¢ Terraform (provisionamento)                                  â”‚
â”‚  â€¢ Docker (containerizaÃ§Ã£o)                                     â”‚
â”‚  â€¢ Docker Compose (dev local)                                   â”‚
â”‚                                                                 â”‚
â”‚  CI/CD:                                                         â”‚
â”‚  â€¢ GitHub Actions (pipelines)                                   â”‚
â”‚  â€¢ Automated testing                                            â”‚
â”‚  â€¢ Linting + type checking                                      â”‚
â”‚  â€¢ Auto-deploy (staging/prod)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Justificativas Arquiteturais

#### Por que esta arquitetura?

**1. SeparaÃ§Ã£o de Camadas (Clean Architecture)**
- **Maintainability**: cada camada pode evoluir independentemente
- **Testability**: fÃ¡cil mockar dependÃªncias
- **Scalability**: escala horizontalmente quando necessÃ¡rio

**2. Data Lake (Bronze/Silver/Gold)**
- **Bronze**: dados brutos preservados (audit trail)
- **Silver**: dados limpos (90% dos casos de uso)
- **Gold**: features agregadas (performance otimizada)
- **Justificativa**: padrÃ£o industry para data pipelines modernos

**3. Dual ML + AI**
- **ML Tradicional**: alta precisÃ£o em detecÃ§Ã£o quantitativa
- **AI Generativa**: explicabilidade e anÃ¡lise qualitativa
- **Justificativa**: combina o melhor dos dois mundos

**4. MicroserviÃ§os Leves**
- **FastAPI**: Ãºnico backend (nÃ£o overengineering)
- **Celery**: tarefas async sem criar serviÃ§os separados
- **Justificativa**: simplicidade para projeto solo, fÃ¡cil evoluir depois

**5. Cloud-Native**
- **ECS Fargate**: sem gerenciar servidores
- **RDS**: database managed (backups automÃ¡ticos)
- **Justificativa**: foco no cÃ³digo, nÃ£o na infra

---

## ðŸ› ï¸ Stack TecnolÃ³gica Completa

### Backend & ML (Python 3.11+)

```toml
[tool.poetry.dependencies]
python = "^3.11"

# ===== CORE WEB FRAMEWORK =====
fastapi = "^0.109.0"              # API REST moderna
uvicorn = {extras = ["standard"], version = "^0.27.0"}  # ASGI server
pydantic = "^2.5.0"               # ValidaÃ§Ã£o de dados
pydantic-settings = "^2.1.0"      # ConfiguraÃ§Ã£o via env vars

# ===== DATA PROCESSING =====
pandas = "^2.2.0"                 # ManipulaÃ§Ã£o de dados
polars = "^0.20.0"                # Alternativa rÃ¡pida ao pandas
pyarrow = "^15.0.0"               # Formato columnar eficiente
numpy = "^1.26.0"                 # ComputaÃ§Ã£o numÃ©rica

# ===== ML TRADICIONAL =====
scikit-learn = "^1.4.0"           # Algoritmos baseline
xgboost = "^2.0.3"                # Modelo principal (gradient boosting)
lightgbm = "^4.3.0"               # Alternativa rÃ¡pida ao XGBoost
optuna = "^3.5.0"                 # Hyperparameter tuning automÃ¡tico
imbalanced-learn = "^0.12.0"      # Lidar com classes desbalanceadas

# ===== MLOPS =====
mlflow = "^2.10.0"                # Tracking + model registry
dvc = {extras = ["s3"], version = "^3.45.0"}  # Versionamento dados/modelos
great-expectations = "^0.18.0"     # Data quality checks

# ===== EXPLICABILIDADE =====
shap = "^0.44.0"                  # SHAP values (model explainability)
lime = "^0.2.0.1"                 # Alternativa ao SHAP

# ===== MODEL SERVING =====
onnx = "^1.15.0"                  # Formato otimizado
onnxruntime = "^1.17.0"           # InferÃªncia rÃ¡pida

# ===== AI GENERATIVA =====
anthropic = "^0.18.0"             # Claude API
openai = "^1.12.0"                # GPT-4 + embeddings
langchain = "^0.1.0"              # Framework LLM
langchain-community = "^0.0.20"   # IntegraÃ§Ãµes community
pinecone-client = "^3.0.0"        # Vector database

# ===== NLP =====
transformers = "^4.37.0"          # Hugging Face models
sentence-transformers = "^2.3.0"   # Embeddings otimizados
torch = "^2.2.0"                  # PyTorch (backend)
spacy = "^3.7.0"                  # NLP industrial

# ===== DATABASE & CACHE =====
sqlalchemy = "^2.0.25"            # ORM
psycopg2-binary = "^2.9.9"        # PostgreSQL driver
alembic = "^1.13.0"               # Migrations
redis = "^5.0.1"                  # Cache + message broker

# ===== ASYNC TASKS =====
celery = "^5.3.6"                 # Distributed task queue
flower = "^2.0.1"                 # Celery monitoring UI

# ===== WEB SCRAPING =====
httpx = "^0.26.0"                 # HTTP client async
beautifulsoup4 = "^4.12.0"        # HTML parsing
scrapy = "^2.11.0"                # Web scraping framework (se necessÃ¡rio)

# ===== ORCHESTRATION =====
prefect = "^2.14.0"               # Workflow orchestration
prefect-aws = "^0.4.0"            # AWS integrations

# ===== MONITORING =====
prometheus-client = "^0.19.0"     # Metrics
sentry-sdk = "^1.40.0"            # Error tracking
evidently = "^0.4.15"             # ML monitoring (drift)

# ===== UTILS =====
python-dotenv = "^1.0.0"          # Env vars
tenacity = "^8.2.3"               # Retry logic
loguru = "^0.7.2"                 # Logging melhorado
python-multipart = "^0.0.6"       # File uploads
jinja2 = "^3.1.3"                 # Templates (reports)

[tool.poetry.group.dev.dependencies]
# ===== TESTING =====
pytest = "^8.0.0"                 # Framework de testes
pytest-cov = "^4.1.0"             # Coverage
pytest-asyncio = "^0.23.0"        # Testes async
pytest-mock = "^3.12.0"           # Mocking
faker = "^22.0.0"                 # Dados fake para testes
httpx = "^0.26.0"                 # Cliente HTTP para testes

# ===== CODE QUALITY =====
ruff = "^0.1.15"                  # Linting + formatting (rÃ¡pido!)
mypy = "^1.8.0"                   # Type checking
pre-commit = "^3.6.0"             # Git hooks
black = "^24.0.0"                 # Code formatter (backup)
isort = "^5.13.0"                 # Import sorting

# ===== NOTEBOOKS =====
jupyter = "^1.0.0"                # Jupyter notebooks
ipykernel = "^6.28.0"             # Kernel
matplotlib = "^3.8.0"             # VisualizaÃ§Ãµes
seaborn = "^0.13.0"               # Plots estatÃ­sticos
plotly = "^5.18.0"                # Plots interativos
```

**Justificativas das Escolhas:**

| Tecnologia | Alternativa | Por que escolhemos |
|------------|-------------|-------------------|
| **FastAPI** | Flask, Django | Async nativo, validaÃ§Ã£o automÃ¡tica, docs gerado |
| **Polars** | SÃ³ Pandas | 10x mais rÃ¡pido, syntax moderna |
| **XGBoost** | Random Forest | State-of-art para tabular, explicÃ¡vel |
| **MLflow** | W&B, Neptune | Open-source, self-hosted, industry standard |
| **Prefect** | Airflow | Mais moderno, Pythonic, cloud gratuito |
| **Anthropic** | SÃ³ OpenAI | Claude Ã© melhor em portuguÃªs, menos censura |
| **Pinecone** | Weaviate, Qdrant | Free tier generoso, docs excelentes |
| **Ruff** | Pylint, Flake8 | 100x mais rÃ¡pido, all-in-one |

---

### Frontend (Next.js 14)

```json
{
  "name": "licitacoes-frontend",
  "version": "1.0.0",
  "dependencies": {
    "next": "14.1.0",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",

    // State & Data Fetching
    "@tanstack/react-query": "^5.17.0",
    "axios": "^1.6.5",
    "swr": "^2.2.4",

    // UI Components
    "@radix-ui/react-dialog": "^1.0.5",
    "@radix-ui/react-dropdown-menu": "^2.0.6",
    "@radix-ui/react-select": "^2.0.0",
    "@radix-ui/react-tabs": "^1.0.4",
    "@radix-ui/react-toast": "^1.1.5",
    "class-variance-authority": "^0.7.0",
    "clsx": "^2.1.0",
    "tailwind-merge": "^2.2.0",

    // Charts & Visualizations
    "recharts": "^2.10.0",
    "d3": "^7.8.5",
    "@visx/visx": "^3.10.0",

    // Forms & Validation
    "react-hook-form": "^7.49.0",
    "zod": "^3.22.4",

    // Utils
    "date-fns": "^3.2.0",
    "lodash": "^4.17.21",

    // PDF Generation
    "jspdf": "^2.5.1",
    "html2canvas": "^1.4.1",

    // Markdown (para explicaÃ§Ãµes LLM)
    "react-markdown": "^9.0.1",
    "remark-gfm": "^4.0.0"
  },
  "devDependencies": {
    "typescript": "^5.3.3",
    "@types/react": "^18.2.48",
    "@types/react-dom": "^18.2.18",
    "@types/node": "^20.11.0",
    "@types/d3": "^7.4.3",

    // Linting & Formatting
    "eslint": "^8.56.0",
    "eslint-config-next": "14.1.0",
    "prettier": "^3.2.0",
    "prettier-plugin-tailwindcss": "^0.5.11",

    // Testing
    "vitest": "^1.2.0",
    "@testing-library/react": "^14.1.2",
    "@testing-library/jest-dom": "^6.2.0",

    // Tailwind
    "tailwindcss": "^3.4.0",
    "autoprefixer": "^10.4.17",
    "postcss": "^8.4.33"
  }
}
```

**Justificativas:**

- **Next.js 14**: App Router, Server Components (performance), streaming
- **shadcn/ui**: Componentes modernos, acessÃ­veis, customizÃ¡veis
- **TanStack Query**: Cache inteligente, refetch automÃ¡tico
- **Recharts**: Simples para 80% dos casos, performÃ¡tico
- **D3**: VisualizaÃ§Ãµes custom quando Recharts nÃ£o serve

---

### Infrastructure & DevOps

```yaml
# Docker
docker: ^24.0.0
docker-compose: ^2.23.0

# Terraform
terraform: ^1.6.0
aws-provider: ^5.0.0

# CI/CD
github-actions: latest

# Cloud (AWS)
aws-cli: ^2.0.0
```

---

## ðŸ“ Estrutura do Projeto

```
licitacoes-ml/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml                          # Tests + linting
â”‚       â”œâ”€â”€ cd-backend.yml                  # Deploy backend to AWS
â”‚       â”œâ”€â”€ cd-frontend.yml                 # Deploy frontend
â”‚       â””â”€â”€ model-retrain.yml               # Weekly retraining
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                         # FastAPI app entry
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ deps.py                     # Dependencies (DB, Redis)
â”‚   â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ router.py               # Main router
â”‚   â”‚   â”‚       â””â”€â”€ endpoints/
â”‚   â”‚   â”‚           â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚           â”œâ”€â”€ predictions.py      # ML predictions
â”‚   â”‚   â”‚           â”œâ”€â”€ explanations.py     # SHAP + LLM
â”‚   â”‚   â”‚           â”œâ”€â”€ search.py           # RAG search
â”‚   â”‚   â”‚           â”œâ”€â”€ edital_analysis.py  # NLP analysis
â”‚   â”‚   â”‚           â”œâ”€â”€ analytics.py        # Dashboards data
â”‚   â”‚   â”‚           â””â”€â”€ health.py           # Health checks
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py                   # Pydantic Settings
â”‚   â”‚   â”‚   â”œâ”€â”€ security.py                 # Auth (se necessÃ¡rio)
â”‚   â”‚   â”‚   â”œâ”€â”€ logging.py                  # Loguru config
â”‚   â”‚   â”‚   â””â”€â”€ metrics.py                  # Prometheus metrics
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py                 # SQLAlchemy models
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py                  # Pydantic schemas (API)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ model_loader.py             # Load ONNX/pickle
â”‚   â”‚   â”‚   â”œâ”€â”€ inference.py                # Prediction logic
â”‚   â”‚   â”‚   â”œâ”€â”€ explainer.py                # SHAP values
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocessing.py            # Feature transforms
â”‚   â”‚   â”‚   â””â”€â”€ monitoring.py               # Drift detection
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_client.py               # Claude/GPT wrappers
â”‚   â”‚   â”‚   â”œâ”€â”€ prompts.py                  # Prompt templates
â”‚   â”‚   â”‚   â”œâ”€â”€ rag.py                      # RAG pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ nlp_analyzer.py             # BERT for editais
â”‚   â”‚   â”‚   â””â”€â”€ embeddings.py               # Vector operations
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ licitacao_service.py        # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ market_price_service.py
â”‚   â”‚   â”‚   â””â”€â”€ cache_service.py            # Redis operations
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ celery_app.py               # Celery config
â”‚   â”‚   â”‚   â””â”€â”€ tasks.py                    # Async tasks
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ database.py                 # DB session
â”‚   â”‚       â”œâ”€â”€ s3.py                       # S3 operations
â”‚   â”‚       â””â”€â”€ validators.py               # Custom validators
â”‚   â”‚
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ conftest.py                     # Pytest fixtures
â”‚   â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_ml_inference.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”‚   â”‚   â””â”€â”€ test_services.py
â”‚   â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_api_predictions.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_rag_pipeline.py
â”‚   â”‚   â”‚   â””â”€â”€ test_database.py
â”‚   â”‚   â””â”€â”€ e2e/
â”‚   â”‚       â””â”€â”€ test_full_pipeline.py
â”‚   â”‚
â”‚   â”œâ”€â”€ alembic/                            # DB migrations
â”‚   â”‚   â”œâ”€â”€ versions/
â”‚   â”‚   â”œâ”€â”€ env.py
â”‚   â”‚   â””â”€â”€ alembic.ini
â”‚   â”‚
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ init_db.py                      # Setup database
â”‚   â”‚   â”œâ”€â”€ seed_data.py                    # Sample data
â”‚   â”‚   â””â”€â”€ health_check.sh                 # Deployment health
â”‚   â”‚
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ .dockerignore
â”‚   â”œâ”€â”€ pyproject.toml                      # Poetry dependencies
â”‚   â”œâ”€â”€ poetry.lock
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ .coveragerc
â”‚   â”œâ”€â”€ pytest.ini
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/                            # DVC tracked
â”‚   â”‚   â”œâ”€â”€ processed/                      # DVC tracked
â”‚   â”‚   â”œâ”€â”€ features/                       # DVC tracked
â”‚   â”‚   â””â”€â”€ external/                       # Reference data
â”‚   â”‚
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_baseline_models.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_model_tuning.ipynb
â”‚   â”‚   â”œâ”€â”€ 05_model_evaluation.ipynb
â”‚   â”‚   â””â”€â”€ 06_explainability.ipynb
â”‚   â”‚
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion.py                # Fetch from APIs
â”‚   â”‚   â”‚   â”œâ”€â”€ validation.py               # Great Expectations
â”‚   â”‚   â”‚   â”œâ”€â”€ cleaning.py                 # Data cleaning
â”‚   â”‚   â”‚   â””â”€â”€ transforms.py               # ETL transforms
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ build_features.py           # Feature engineering
â”‚   â”‚   â”‚   â”œâ”€â”€ feature_selection.py        # Select best features
â”‚   â”‚   â”‚   â””â”€â”€ encoders.py                 # Custom encoders
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py                    # Training script
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluate.py                 # Evaluation metrics
â”‚   â”‚   â”‚   â”œâ”€â”€ tune.py                     # Optuna tuning
â”‚   â”‚   â”‚   â”œâ”€â”€ explain.py                  # SHAP generation
â”‚   â”‚   â”‚   â””â”€â”€ export.py                   # Export to ONNX
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ mlflow_utils.py             # MLflow helpers
â”‚   â”‚       â”œâ”€â”€ data_loader.py              # Load datasets
â”‚   â”‚       â””â”€â”€ metrics.py                  # Custom metrics
â”‚   â”‚
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ingestion_flow.py               # Prefect flow
â”‚   â”‚   â”œâ”€â”€ training_flow.py                # Training pipeline
â”‚   â”‚   â””â”€â”€ deployment_flow.py              # Model deployment
â”‚   â”‚
â”‚   â”œâ”€â”€ configs/
â”‚   â”‚   â”œâ”€â”€ model_config.yaml               # Model hyperparams
â”‚   â”‚   â”œâ”€â”€ feature_config.yaml             # Feature definitions
â”‚   â”‚   â””â”€â”€ data_quality_config.yaml        # GE expectations
â”‚   â”‚
â”‚   â”œâ”€â”€ mlruns/                             # MLflow tracking (gitignore)
â”‚   â”œâ”€â”€ models/                             # Trained models (DVC)
â”‚   â”‚
â”‚   â”œâ”€â”€ dvc.yaml                            # DVC pipeline
â”‚   â”œâ”€â”€ dvc.lock
â”‚   â”œâ”€â”€ params.yaml                         # DVC parameters
â”‚   â”œâ”€â”€ .dvc/
â”‚   â”œâ”€â”€ .dvcignore
â”‚   â”‚
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ setup.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ layout.tsx                      # Root layout
â”‚   â”‚   â”œâ”€â”€ page.tsx                        # Home page
â”‚   â”‚   â”œâ”€â”€ globals.css
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx                    # Main dashboard
â”‚   â”‚   â”‚   â””â”€â”€ layout.tsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ licitacoes/
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx                    # List view
â”‚   â”‚   â”‚   â””â”€â”€ [id]/
â”‚   â”‚   â”‚       â””â”€â”€ page.tsx                # Detail view
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ busca/
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx                    # RAG search interface
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ analytics/
â”‚   â”‚       â””â”€â”€ page.tsx                    # Analytics dashboard
â”‚   â”‚
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ui/                             # shadcn/ui components
â”‚   â”‚   â”‚   â”œâ”€â”€ button.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ card.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ dialog.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ charts/
â”‚   â”‚   â”‚   â”œâ”€â”€ PriceComparisonChart.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ShapPlot.tsx
â”‚   â”‚   â”‚   â””â”€â”€ TimeSeriesChart.tsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ licitacao/
â”‚   â”‚   â”‚   â”œâ”€â”€ LicitacaoCard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ LicitacaoFilters.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ExplanationPanel.tsx
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ shared/
â”‚   â”‚       â”œâ”€â”€ Header.tsx
â”‚   â”‚       â”œâ”€â”€ Footer.tsx
â”‚   â”‚       â””â”€â”€ Loading.tsx
â”‚   â”‚
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ api-client.ts                   # Axios instance
â”‚   â”‚   â”œâ”€â”€ utils.ts                        # Utility functions
â”‚   â”‚   â”œâ”€â”€ types.ts                        # TypeScript types
â”‚   â”‚   â””â”€â”€ constants.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useLicitacoes.ts
â”‚   â”‚   â”œâ”€â”€ usePrediction.ts
â”‚   â”‚   â””â”€â”€ useSearch.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â””â”€â”€ icons/
â”‚   â”‚
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ .dockerignore
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ next.config.js
â”‚   â”œâ”€â”€ tailwind.config.ts
â”‚   â”œâ”€â”€ postcss.config.js
â”‚   â”œâ”€â”€ .eslintrc.json
â”‚   â”œâ”€â”€ .prettierrc
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ terraform/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”‚   â”œâ”€â”€ ecs/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ outputs.tf
â”‚   â”‚   â”‚   â”œâ”€â”€ rds/
â”‚   â”‚   â”‚   â”œâ”€â”€ s3/
â”‚   â”‚   â”‚   â”œâ”€â”€ elasticache/
â”‚   â”‚   â”‚   â””â”€â”€ networking/
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ environments/
â”‚   â”‚       â”œâ”€â”€ dev/
â”‚   â”‚       â”‚   â””â”€â”€ terraform.tfvars
â”‚   â”‚       â””â”€â”€ prod/
â”‚   â”‚           â””â”€â”€ terraform.tfvars
â”‚   â”‚
â”‚   â”œâ”€â”€ docker-compose.yml                  # Local development
â”‚   â”œâ”€â”€ docker-compose.prod.yml             # Production-like
â”‚   â”‚
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ prometheus.yml
â”‚       â”œâ”€â”€ grafana-dashboards/
â”‚       â”‚   â”œâ”€â”€ ml-metrics.json
â”‚       â”‚   â””â”€â”€ api-performance.json
â”‚       â””â”€â”€ alertmanager.yml
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ api-documentation.md
â”‚   â”œâ”€â”€ ml-methodology.md
â”‚   â”œâ”€â”€ deployment-guide.md
â”‚   â”œâ”€â”€ data-dictionary.md
â”‚   â”œâ”€â”€ contributing.md
â”‚   â””â”€â”€ images/
â”‚       â”œâ”€â”€ architecture-diagram.png
â”‚       â””â”€â”€ screenshots/
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_local.sh                      # Setup dev environment
â”‚   â”œâ”€â”€ run_tests.sh                        # Run all tests
â”‚   â”œâ”€â”€ deploy_dev.sh                       # Deploy to dev
â”‚   â”œâ”€â”€ deploy_prod.sh                      # Deploy to prod
â”‚   â””â”€â”€ backup_db.sh                        # Database backup
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .pre-commit-config.yaml
â”œâ”€â”€ Makefile                                # Common commands
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md                               # Main documentation
â”œâ”€â”€ LICENSE
â””â”€â”€ CHANGELOG.md
```

---

## ðŸ“… Roadmap Detalhado - 5 Meses

### **MÃªs 1: FundaÃ§Ã£o e Data Pipeline** (Semanas 1-4)

#### **Semana 1: Setup & Arquitetura**
**Objetivo**: Ambiente de desenvolvimento funcionando

**Tarefas:**
- [ ] Criar repositÃ³rio GitHub (pÃºblico)
- [ ] Setup estrutura de pastas completa
- [ ] Configurar Poetry + pyproject.toml
- [ ] Docker Compose: PostgreSQL + Redis + MLflow
- [ ] Setup DVC com S3 local (MinIO)
- [ ] Configurar pre-commit hooks
- [ ] GitHub Actions: CI bÃ¡sico (linting)
- [ ] README inicial com instruÃ§Ãµes setup

**Deliverables:**
- âœ… Projeto roda com `docker-compose up`
- âœ… CI passando (mesmo sem cÃ³digo)
- âœ… DocumentaÃ§Ã£o de setup

**Tempo estimado**: 35-40 horas

---

#### **Semana 2: Schema de Dados & IngestÃ£o**
**Objetivo**: Primeiros dados no sistema

**Tarefas:**
- [ ] Pesquisar APIs disponÃ­veis (PNCP, Compras.gov)
- [ ] Definir schema PostgreSQL (staging + dwh)
- [ ] Criar models SQLAlchemy
- [ ] Implementar cliente API PNCP
- [ ] Script de ingestÃ£o inicial
- [ ] Great Expectations: data quality suite
- [ ] Coletar 10k+ licitaÃ§Ãµes

**Deliverables:**
- âœ… Schema documentado (data dictionary)
- âœ… 10k licitaÃ§Ãµes no PostgreSQL
- âœ… Data quality checks passando

**Tempo estimado**: 40-45 horas

---

#### **Semana 3: ETL Pipeline**
**Objetivo**: Pipeline automatizado de dados

**Tarefas:**
- [ ] Setup Prefect Cloud (free tier)
- [ ] Criar flow de ingestÃ£o diÃ¡ria
- [ ] Implementar data cleaning
- [ ] Criar camadas bronze/silver/gold no S3
- [ ] Tracking DVC dos datasets
- [ ] Scheduler: rodar diariamente
- [ ] Monitoramento bÃ¡sico (logs)

**Deliverables:**
- âœ… Pipeline rodando automaticamente
- âœ… Dados versionados (DVC)
- âœ… 50k+ licitaÃ§Ãµes coletadas

**Tempo estimado**: 35-40 horas

---

#### **Semana 4: Coleta de PreÃ§os de Mercado**
**Objetivo**: Baseline para comparaÃ§Ã£o

**Tarefas:**
- [ ] Identificar fontes de preÃ§os (SINAPI, scraping)
- [ ] Implementar scraping Ã©tico (rate limit)
- [ ] Normalizar categorias de produtos
- [ ] Join licitaÃ§Ãµes â†” preÃ§os mercado
- [ ] AnÃ¡lise de cobertura (% com preÃ§o)
- [ ] Documentar fontes e metodologia

**Deliverables:**
- âœ… Tabela `market_prices` populada
- âœ… 70%+ licitaÃ§Ãµes com preÃ§o de referÃªncia
- âœ… Metodologia documentada

**Tempo estimado**: 35-40 horas

**Total MÃªs 1**: ~150 horas (37.5h/semana)

---

### **MÃªs 2: Feature Engineering & EDA** (Semanas 5-8)

#### **Semana 5: AnÃ¡lise ExploratÃ³ria**
**Objetivo**: Entender profundamente os dados

**Tarefas:**
- [ ] Setup Jupyter Lab
- [ ] Notebook: distribuiÃ§Ãµes de preÃ§os
- [ ] AnÃ¡lise por categoria, regiÃ£o, Ã³rgÃ£o
- [ ] Identificar outliers Ã³bvios
- [ ] AnÃ¡lise temporal (sazonalidade?)
- [ ] CorrelaÃ§Ãµes entre variÃ¡veis
- [ ] Pandas Profiling report

**Deliverables:**
- âœ… Notebook `01_data_exploration.ipynb`
- âœ… RelatÃ³rio de insights (3-5 pÃ¡ginas)
- âœ… HipÃ³teses para features

**Tempo estimado**: 35-40 horas

---

#### **Semana 6: Feature Engineering - Parte 1**
**Objetivo**: Features numÃ©ricas e agregaÃ§Ãµes

**Tarefas:**
- [ ] Feature: desvio do preÃ§o mÃ©dio
- [ ] Feature: percentil por categoria
- [ ] Feature: histÃ³rico do fornecedor
- [ ] Feature: tempo desde Ãºltima licitaÃ§Ã£o
- [ ] Feature: valor per capita (populaÃ§Ã£o)
- [ ] Feature: sazonalidade (mÃªs, trimestre)
- [ ] Feature: complexidade do edital (tamanho)
- [ ] Pipeline de transformaÃ§Ã£o

**Deliverables:**
- âœ… 15+ features numÃ©ricas
- âœ… Pipeline reproduzÃ­vel
- âœ… Notebook documentado

**Tempo estimado**: 40-45 horas

---

#### **Semana 7: Feature Engineering - Parte 2**
**Objetivo**: Features categÃ³ricas e interaÃ§Ãµes

**Tarefas:**
- [ ] Encoding de categorias (target encoding)
- [ ] Features de interaÃ§Ã£o (categoria Ã— regiÃ£o)
- [ ] Features de texto (editais)
- [ ] TF-IDF de descriÃ§Ãµes (se houver)
- [ ] Feature selection (correlaÃ§Ã£o, importÃ¢ncia)
- [ ] ValidaÃ§Ã£o de features (nÃ£o vazam futuro)
- [ ] Documentar cada feature

**Deliverables:**
- âœ… 30+ features totais
- âœ… Feature importance analysis
- âœ… DicionÃ¡rio de features completo

**Tempo estimado**: 40-45 horas

---

#### **Semana 8: Target Definition & Dataset Final**
**Objetivo**: Dataset pronto para ML

**Tarefas:**
- [ ] Definir target: sobrepreÃ§o (binÃ¡rio? regressÃ£o?)
- [ ] EstratÃ©gia de labeling (threshold? manual?)
- [ ] Train/validation/test split (temporal)
- [ ] AnÃ¡lise de desbalanceamento
- [ ] Estratificar splits
- [ ] Salvar datasets finais (DVC)
- [ ] Dataset quality checks

**Deliverables:**
- âœ… Dataset ML-ready (train/val/test)
- âœ… Target bem definido e documentado
- âœ… AnÃ¡lise de desbalanceamento

**Tempo estimado**: 30-35 horas

**Total MÃªs 2**: ~150 horas

---

### **MÃªs 3: Machine Learning** (Semanas 9-12)

#### **Semana 9: Baseline Models**
**Objetivo**: Estabelecer baseline de performance

**Tarefas:**
- [ ] Setup MLflow tracking
- [ ] Dummy classifier (baseline ingÃªnuo)
- [ ] Logistic Regression
- [ ] Random Forest
- [ ] XGBoost (default params)
- [ ] Cross-validation (5-fold)
- [ ] Definir mÃ©tricas primÃ¡rias (precision, recall)
- [ ] AnÃ¡lise de erros

**Deliverables:**
- âœ… 4-5 modelos baseline
- âœ… MLflow com experimentos
- âœ… Baseline performance report

**Tempo estimado**: 35-40 horas

---

#### **Semana 10: Model Tuning**
**Objetivo**: Otimizar modelo de produÃ§Ã£o

**Tarefas:**
- [ ] Setup Optuna
- [ ] Hyperparameter tuning XGBoost (100+ trials)
- [ ] Tuning LightGBM
- [ ] Ensemble (XGBoost + LightGBM)
- [ ] Threshold tuning (precision/recall tradeoff)
- [ ] CalibraÃ§Ã£o de probabilidades
- [ ] ValidaÃ§Ã£o no test set

**Deliverables:**
- âœ… Modelo otimizado (>85% precision)
- âœ… Optuna study salvo
- âœ… MÃ©tricas finais documentadas

**Tempo estimado**: 40-45 horas

---

#### **Semana 11: Explainability**
**Objetivo**: Entender e explicar prediÃ§Ãµes

**Tarefas:**
- [ ] SHAP values (global + local)
- [ ] Feature importance (gain, cover, freq)
- [ ] Partial dependence plots
- [ ] LIME (alternativa ao SHAP)
- [ ] AnÃ¡lise de casos extremos
- [ ] Criar explainer reutilizÃ¡vel
- [ ] Notebook de explicabilidade

**Deliverables:**
- âœ… SHAP explainer treinado
- âœ… VisualizaÃ§Ãµes de explicabilidade
- âœ… Notebook `05_explainability.ipynb`

**Tempo estimado**: 30-35 horas

---

#### **Semana 12: Model Registry & Export**
**Objetivo**: Modelo pronto para produÃ§Ã£o

**Tarefas:**
- [ ] Registrar modelo no MLflow
- [ ] Export para ONNX
- [ ] Validar ONNX (mesmas prediÃ§Ãµes)
- [ ] Benchmark de latÃªncia
- [ ] Model card (documentaÃ§Ã£o)
- [ ] Criar inference pipeline
- [ ] Testes unitÃ¡rios do modelo

**Deliverables:**
- âœ… Modelo em ONNX otimizado
- âœ… LatÃªncia <100ms (p99)
- âœ… Model card completo

**Tempo estimado**: 35-40 horas

**Total MÃªs 3**: ~145 horas

---

### **MÃªs 4: Backend API & AI Layer** (Semanas 13-16)

#### **Semana 13: FastAPI Core**
**Objetivo**: API bÃ¡sica funcionando

**Tarefas:**
- [ ] Setup FastAPI + estrutura
- [ ] Config (Pydantic Settings)
- [ ] Database connection pool
- [ ] Redis connection
- [ ] Model loading (singleton)
- [ ] Endpoint: POST /v1/predict
- [ ] Endpoint: GET /v1/health
- [ ] Swagger docs configurado

**Deliverables:**
- âœ… API rodando localmente
- âœ… Endpoint de prediÃ§Ã£o funcional
- âœ… Swagger UI acessÃ­vel

**Tempo estimado**: 35-40 horas

---

#### **Semana 14: API Features & Testing**
**Objetivo**: API production-ready

**Tarefas:**
- [ ] Endpoint: POST /v1/explain (SHAP)
- [ ] Endpoint: POST /v1/batch (lote)
- [ ] Rate limiting (SlowAPI)
- [ ] Caching (Redis - 24h TTL)
- [ ] Error handling robusto
- [ ] Logging estruturado (Loguru)
- [ ] Testes unitÃ¡rios (pytest)
- [ ] Testes de integraÃ§Ã£o
- [ ] Coverage >85%

**Deliverables:**
- âœ… API completa (CRUD)
- âœ… Testes passando (>85% coverage)
- âœ… Performance benchmarks

**Tempo estimado**: 40-45 horas

---

#### **Semana 15: AI Layer - LLM Integration**
**Objetivo**: Adicionar inteligÃªncia generativa

**Tarefas:**
- [ ] Setup Anthropic SDK
- [ ] Criar prompt templates
- [ ] FunÃ§Ã£o: explain_to_citizen()
- [ ] Endpoint: POST /v1/explain-llm
- [ ] Streaming responses (Server-Sent Events)
- [ ] Token usage tracking
- [ ] Cost monitoring
- [ ] Fallback (se API falhar)
- [ ] Testes com mocks

**Deliverables:**
- âœ… ExplicaÃ§Ãµes em linguagem natural
- âœ… Streaming funcionando
- âœ… Cost tracking implementado

**Tempo estimado**: 35-40 horas

---

#### **Semana 16: RAG System**
**Objetivo**: Busca semÃ¢ntica de editais

**Tarefas:**
- [ ] Setup Pinecone (free tier)
- [ ] Indexar editais (embeddings)
- [ ] Implementar chunking strategy
- [ ] RAG pipeline (retrieve + generate)
- [ ] Endpoint: POST /v1/search
- [ ] Relevance scoring
- [ ] Cache de embeddings
- [ ] Testes de relevÃ¢ncia

**Deliverables:**
- âœ… RAG funcional
- âœ… Busca semÃ¢ntica precisa
- âœ… Endpoint documentado

**Tempo estimado**: 40-45 horas

**Total MÃªs 4**: ~155 horas

---

### **MÃªs 5: Frontend, Deploy & Polish** (Semanas 17-20)

#### **Semana 17: Frontend - Core**
**Objetivo**: Dashboard bÃ¡sico funcionando

**Tarefas:**
- [ ] Setup Next.js 14 + TypeScript
- [ ] Configurar shadcn/ui
- [ ] API client (Axios + TanStack Query)
- [ ] Layout base (Header, Footer)
- [ ] PÃ¡gina: Dashboard (KPIs)
- [ ] PÃ¡gina: Lista de licitaÃ§Ãµes
- [ ] PÃ¡gina: Detalhe de licitaÃ§Ã£o
- [ ] Responsivo (mobile-first)

**Deliverables:**
- âœ… Frontend rodando localmente
- âœ… 3 pÃ¡ginas principais
- âœ… UX polido

**Tempo estimado**: 40-45 horas

---

#### **Semana 18: Frontend - Features AvanÃ§adas**
**Objetivo**: Diferenciais visuais

**Tarefas:**
- [ ] GrÃ¡fico: comparaÃ§Ã£o preÃ§o (Recharts)
- [ ] GrÃ¡fico: SHAP waterfall (D3.js)
- [ ] Streaming de explicaÃ§Ãµes LLM
- [ ] Busca semÃ¢ntica (interface RAG)
- [ ] ExportaÃ§Ã£o PDF (jsPDF)
- [ ] Filtros avanÃ§ados
- [ ] Loading states + errors
- [ ] Dark mode (opcional)

**Deliverables:**
- âœ… VisualizaÃ§Ãµes impressionantes
- âœ… Explicabilidade visual
- âœ… RelatÃ³rios exportÃ¡veis

**Tempo estimado**: 40-45 horas

---

#### **Semana 19: Deploy & Infrastructure**
**Objetivo**: Sistema em produÃ§Ã£o

**Tarefas:**
- [ ] Dockerfile backend (multi-stage)
- [ ] Dockerfile frontend
- [ ] Terraform: ECS Fargate
- [ ] Terraform: RDS PostgreSQL
- [ ] Terraform: ElastiCache Redis
- [ ] Terraform: S3
- [ ] Terraform: ALB + HTTPS
- [ ] GitHub Actions: CD pipeline
- [ ] Secrets management (AWS Secrets Manager)
- [ ] Deploy staging + prod

**Deliverables:**
- âœ… App rodando em AWS
- âœ… URL pÃºblica (HTTPS)
- âœ… CI/CD automatizado

**Tempo estimado**: 45-50 horas

---

#### **Semana 20: Monitoring, Docs & Launch**
**Objetivo**: Projeto pronto para apresentar

**Tarefas:**
- [ ] Prometheus + Grafana dashboards
- [ ] Evidently AI (drift detection)
- [ ] Sentry error tracking
- [ ] README de nÃ­vel mundial
- [ ] docs/ completo (arquitetura, API, ML)
- [ ] Video demo (5 minutos)
- [ ] LinkedIn post
- [ ] Medium article (opcional)
- [ ] Portfolio update

**Deliverables:**
- âœ… Monitoring completo
- âœ… DocumentaÃ§Ã£o impecÃ¡vel
- âœ… Video demo no YouTube
- âœ… PresenÃ§a online

**Tempo estimado**: 40-45 horas

**Total MÃªs 5**: ~170 horas

---

## **TOTAL PROJETO: ~770 horas (~38h/semana)**


## âœ… RESUMO DO PROJETO COMPLETO

### O que vocÃª vai construir:

**Sistema HÃ­brido de DetecÃ§Ã£o de SobrepreÃ§o em LicitaÃ§Ãµes**
- **ML Tradicional** (XGBoost) â†’ detecÃ§Ã£o quantitativa de anomalias
- **AI Generativa** (Claude/GPT) â†’ explicabilidade e anÃ¡lise qualitativa
- **NLP** (BERT) â†’ anÃ¡lise de clÃ¡usulas em editais
- **RAG** (Pinecone) â†’ busca semÃ¢ntica de licitaÃ§Ãµes similares

---

## ðŸ“Š ENTREGAS FINAIS (5 meses)

### **Produto Final:**

1. **Backend API (FastAPI)**
   - `/predict` - detecÃ§Ã£o ML tradicional
   - `/explain` - explicaÃ§Ãµes LLM + SHAP
   - `/search` - busca semÃ¢ntica (RAG)
   - `/analyze-edital` - NLP de clÃ¡usulas
   - LatÃªncia <100ms, 90%+ coverage de testes

2. **Frontend (Next.js 14)**
   - Dashboard com KPIs e alertas
   - AnÃ¡lise individual de licitaÃ§Ãµes
   - VisualizaÃ§Ã£o de explicabilidade (SHAP plots)
   - Comparativos preÃ§o licitaÃ§Ã£o vs mercado
   - ExportaÃ§Ã£o de relatÃ³rios PDF

3. **Infraestrutura (AWS)**
   - ECS Fargate (backend)
   - RDS PostgreSQL (dados)
   - S3 (data lake)
   - ElastiCache Redis (cache)
   - Terraform (IaC)
   - CI/CD completo (GitHub Actions)

4. **MLOps Pipeline**
   - Prefect (orquestraÃ§Ã£o)
   - MLflow (tracking)
   - DVC (versionamento)
   - Great Expectations (data quality)
   - Evidently AI (drift detection)

5. **DocumentaÃ§Ã£o**
   - README nÃ­vel mundial
   - Architecture docs
   - API documentation
   - ML methodology paper
   - Video demo (5 min)

---

## ðŸŽ¯ CRONOGRAMA FINAL - 5 MESES

| MÃªs | Foco | Horas | Entregas Principais |
|-----|------|-------|---------------------|
| **1** | Data Pipeline | 150h | 50k+ licitaÃ§Ãµes coletadas, pipeline automatizado |
| **2** | Feature Engineering | 150h | 30+ features, dataset ML-ready |
| **3** | ML Models | 145h | Modelo XGBoost (87%+ precision), SHAP explainer |
| **4** | Backend + AI | 155h | API completa, LLM integration, RAG system |
| **5** | Frontend + Deploy | 170h | Dashboard, app em produÃ§Ã£o (AWS), monitoring |
| **TOTAL** | | **770h** | **Sistema completo end-to-end** |

**DedicaÃ§Ã£o:** ~38h/semana (7-8h/dia, 5 dias/semana)

---

## ðŸ† DIFERENCIAIS PARA VAGAS

### **Para ML Engineer:**
âœ… Pipeline completo de dados (ETL, quality, versionamento)
âœ… Feature engineering sofisticado (30+ features)
âœ… MLOps production-ready (MLflow, DVC, monitoring)
âœ… Model serving otimizado (ONNX, <100ms)
âœ… Testes automatizados (>85% coverage)

### **Para AI Engineer:**
âœ… LLM integration (Claude API, prompt engineering)
âœ… RAG system (Pinecone, embeddings, semantic search)
âœ… NLP aplicado (BERT, anÃ¡lise de editais)
âœ… Explicabilidade (SHAP visual + narrativa LLM)
âœ… Multi-modal (dados tabulares + texto)

---

## ðŸ“ˆ MÃ‰TRICAS DE SUCESSO

### **TÃ©cnicas:**
- âœ… Modelo: Precision >85%, Recall >80%
- âœ… API: LatÃªncia p99 <100ms
- âœ… Testes: Coverage >85%
- âœ… Uptime: >99% (apÃ³s deploy)
- âœ… Data Quality: 100% de validaÃ§Ãµes passando

### **Portfolio:**
- âœ… GitHub: >1000 linhas de cÃ³digo bem estruturado
- âœ… README: >2000 palavras, diagramas, screenshots
- âœ… Video Demo: 5 minutos, profissional
- âœ… DocumentaÃ§Ã£o: 5+ docs tÃ©cnicos completos
- âœ… App Live: URL pÃºblica funcionando

### **Carreira:**
- âœ… **Objetivo:** Primeiro emprego ML/AI Engineer
- âœ… **Timeline:** ComeÃ§ar aplicar no mÃªs 4-5
- âœ… **Meta:** 3-5 entrevistas tÃ©cnicas atÃ© mÃªs 6

---

## ðŸ› ï¸ STACK FINAL

### **Core Technologies:**

**Backend/ML:**
```
Python 3.11 + FastAPI + SQLAlchemy
XGBoost + LightGBM + MLflow
Anthropic (Claude) + OpenAI (GPT-4)
Pinecone + BERT + SHAP
PostgreSQL + Redis + S3
Prefect + DVC + Great Expectations
```

**Frontend:**
```
Next.js 14 + TypeScript
shadcn/ui + Tailwind CSS
TanStack Query + Recharts + D3.js
```

**Infrastructure:**
```
Docker + Terraform
AWS ECS Fargate + RDS + S3
GitHub Actions (CI/CD)
Prometheus + Grafana + Sentry
```

---

## ðŸ“‹ CHECKLIST FINAL DE ENTREGA

### **Antes de Aplicar para Vagas:**

**CÃ³digo:**
- [ ] >85% test coverage
- [ ] Zero warnings de linting
- [ ] Type hints em 100% do cÃ³digo
- [ ] DocumentaÃ§Ã£o inline (docstrings)

**Deploy:**
- [ ] App rodando em produÃ§Ã£o (URL pÃºblica)
- [ ] HTTPS configurado
- [ ] Monitoring ativo (Grafana)
- [ ] CI/CD funcionando

**DocumentaÃ§Ã£o:**
- [ ] README impressionante
- [ ] 5+ docs tÃ©cnicos completos
- [ ] Diagramas visuais
- [ ] Screenshots/GIFs

**PresenÃ§a:**
- [ ] Video demo no YouTube
- [ ] LinkedIn post sobre o projeto
- [ ] Portfolio atualizado
- [ ] GitHub profile polido

**PreparaÃ§Ã£o:**
- [ ] Consegue explicar TODAS as decisÃµes tÃ©cnicas
- [ ] Conhece limitaÃ§Ãµes do projeto (seja honesto)
- [ ] Sabe dizer "o que faria diferente"
- [ ] Preparado para live coding (refactor de alguma parte)

---
